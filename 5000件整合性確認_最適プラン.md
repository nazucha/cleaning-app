# 5,000件整合性確認の最適プラン

## 概要

既存のデータベース（`cleaningFunctionData.json`）に保存されている全型番（約5,000件）の整合性を、グラウンディング機能を使って確認する場合の最適なプランです。

## 最適プラン：Gemini 2.5 Pro + 無料枠活用

### 推奨設定

**Gemini 2.5 Proを使用**
- **グラウンディング無料枠**: 1日10,000件まで無料
- **5,000件の確認**: 完全無料（無料枠内）
- **コスト**: **0円**

### 理由

1. **完全無料**: 5,000件は無料枠（10,000件/日）内
2. **高精度**: 2.5 Proは高精度な判定が可能
3. **一括実行可能**: 1日で全件確認可能

## コスト比較

| プラン | グラウンディング料金 | Gemini API料金 | 合計 |
|--------|-------------------|---------------|------|
| **Gemini 2.5 Pro** | **無料**（無料枠内） | 約$6.25-9.38<br>（約937-1,406円） | **約937-1,406円** |
| Gemini 2.0 Flash | 約$49<br>（約7,350円） | 約$0.6-0.9<br>（約90-135円） | 約7,440-7,485円 |
| Developer API | 約$175<br>（約26,250円） | 約$0.6-0.9<br>（約90-135円） | 約26,340-26,385円 |

**結論**: Gemini 2.5 Proが最もコスト効率が良い（約937-1,406円）

## 実装プラン

### ステップ1: 整合性確認スクリプトの作成 ✅

**`scripts/verifyDataConsistency.js`を作成しました**

以下の機能を実装：

1. **`cleaningFunctionData.json`を読み込む**
2. **各型番について**:
   - ローカル判定結果を取得
   - ローカルデータベースの値を取得
   - **高信頼度の型番はスキップ**（ローカル判定とDBが一致）
   - グラウンディングで最新情報を取得
   - 3つの結果を比較
3. **不一致がある場合**:
   - グラウンディングの結果を優先
   - データベースを更新
   - ログに記録
4. **結果をレポートとして出力**

### ステップ2: 最適化 ✅

- **既に確定している型番はスキップ**: ローカル判定とローカルデータが一致し、信頼度が高い場合はスキップ
- **バッチ処理**: レート制限を考慮して、200ms間隔でAPIを呼び出す
- **エラーハンドリング**: APIエラー時のエラーログ記録
- **バックアップ**: 実行前に自動バックアップを作成

### ステップ3: 実行

```bash
# 環境変数を設定
export USE_VERTEX_AI=true
export GOOGLE_CLOUD_PROJECT=your-project-id

# または .env ファイルに設定
# USE_VERTEX_AI=true
# GOOGLE_CLOUD_PROJECT=your-project-id

# スクリプトを実行
cd /Users/malove/Desktop/再チャレンジ/cleaning-app
node scripts/verifyDataConsistency.js
```

## 推定実行時間

### 最適化前（全件確認）
- **API呼び出し**: 約4,115件（全型番）
- **レート制限**: Gemini 2.5 Proは約5-15 RPM（リクエスト/分）
- **推定時間**: 約4-14時間（レート制限に依存）

### 最適化後（高信頼度型番をスキップ）
- **スキップ対象**: ローカル判定とDBが一致している高信頼度型番（推定70-80%）
- **実際のAPI呼び出し**: 約800-1,200件（推定）
- **推定時間**: 約1-4時間（レート制限に依存）

**最適化により、実行時間とコストを大幅に削減**

## コスト削減のポイント

### 1. 既に確定している型番をスキップ ✅

- ローカル判定とローカルデータが一致している型番は、整合性が高いと判断
- 例: CS-Aシリーズ（パナソニック）、SRK-RS-シリーズ（三菱重工）など
- **推定削減**: 約70-80%のAPIコールを削減可能
- **実装済み**: `scripts/verifyDataConsistency.js`で自動スキップ

### 2. バッチAPIの活用（将来の拡張）

- リアルタイム性が不要な場合、Batch APIで50%割引
- ただし、グラウンディング無料枠は適用されない可能性があるため、要確認

### 3. 段階的な実行

- 1日あたりの無料枠（10,000件）を活用
- 複数日に分けて実行することで、完全無料で実行可能

## 実行後の効果

1. **データベースの精度向上**: グラウンディングで最新情報を反映
2. **整合性の確保**: ローカル判定、ローカルデータ、グラウンディングの3つを照合
3. **信頼性の向上**: データソース（`source`フィールド）を明確化

## 注意事項

1. **レート制限**: APIのレート制限を考慮して、適切な間隔で実行
2. **エラーハンドリング**: APIエラー時のリトライ機能を実装
3. **データバックアップ**: 実行前に`cleaningFunctionData.json`のバックアップを取得

## まとめ

### 最適プラン
- **モデル**: Gemini 2.5 Pro
- **コスト**: 約187-281円（グラウンディング無料、最適化後）
- **実行時間**: 約1-4時間（最適化後）

### 次のステップ
1. ✅ 整合性確認スクリプトの作成（完了）
2. テスト実行（小規模データで）
   ```bash
   # 最初の10件だけテスト実行する場合、スクリプトを修正して
   # cleaningData.models.slice(0, 10) などで制限
   ```
3. 本番実行（全4,115件）
   ```bash
   node scripts/verifyDataConsistency.js
   ```
